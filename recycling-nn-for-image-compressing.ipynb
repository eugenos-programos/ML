{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import libraries**","metadata":{"id":"2JVlY7Zy5AMJ","execution":{"iopub.status.busy":"2022-10-23T12:06:24.043676Z","iopub.execute_input":"2022-10-23T12:06:24.044702Z","iopub.status.idle":"2022-10-23T12:06:24.294876Z","shell.execute_reply.started":"2022-10-23T12:06:24.044589Z","shell.execute_reply":"2022-10-23T12:06:24.293660Z"}}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-10-25T20:56:44.795989Z","iopub.execute_input":"2022-10-25T20:56:44.796357Z","iopub.status.idle":"2022-10-25T20:56:44.803034Z","shell.execute_reply.started":"2022-10-25T20:56:44.796323Z","shell.execute_reply":"2022-10-25T20:56:44.801945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data preprocessing**","metadata":{}},{"cell_type":"code","source":"DATA_PATH = '../input/png-files-256-x-256/pngs'\nIMAGE_SHAPE = (256, 256, 3)\nIMAGE_SIZE = IMAGE_SHAPE[0]","metadata":{"id":"J8Ea6SRt7NBU","execution":{"iopub.status.busy":"2022-10-25T19:44:23.350075Z","iopub.execute_input":"2022-10-25T19:44:23.350423Z","iopub.status.idle":"2022-10-25T19:44:23.355378Z","shell.execute_reply.started":"2022-10-25T19:44:23.350394Z","shell.execute_reply":"2022-10-25T19:44:23.354299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_img(img_matrix):\n    cv2_imshow(img_matrix)\n\ndef get_shape(data):\n    return data.shape, data.reshape(-1).shape[0]\n\ndef get_blocks_params(block_height, block_width, img_size):\n    horiz_blocks_num = img_size // block_height\n    vert_blocks_num = img_size // block_width\n    return horiz_blocks_num, vert_blocks_num,\\\n         horiz_blocks_num * vert_blocks_num\n\ndef normalize_data(data):\n    return data * (2 / np.max(data)) - 1\n\ndef check_image_shape(img_matrix):\n    if img_matrix.shape != IMAGE_SHAPE:\n        print(\"Wrong shape - {}\".format(img_matrix.shape))","metadata":{"id":"T-Q3GJzZ6JLj","execution":{"iopub.status.busy":"2022-10-25T19:51:46.752414Z","iopub.execute_input":"2022-10-25T19:51:46.752799Z","iopub.status.idle":"2022-10-25T19:51:46.760782Z","shell.execute_reply.started":"2022-10-25T19:51:46.752769Z","shell.execute_reply":"2022-10-25T19:51:46.759548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset uploading","metadata":{}},{"cell_type":"code","source":"for adr, dirs, file_names in os.walk(DATA_PATH):\n    n_files = len(file_names)\n    train_data = np.zeros(shape=(n_files, *IMAGE_SHAPE))\n    for file_index, file_name in enumerate(file_names):\n        img = cv2.imread(adr + '/' + file_name)\n        check_image_shape(img)\n        train_data[file_index] = normalize_data(img)\n    print(\"Dataset uploaded. All images have correct shape.\")\n        \nprint('Dataset shape - {}, total number of pixels - {}'.format(*get_shape(train_data)))","metadata":{"execution":{"iopub.status.busy":"2022-10-25T19:44:25.369308Z","iopub.execute_input":"2022-10-25T19:44:25.369717Z","iopub.status.idle":"2022-10-25T19:44:45.744716Z","shell.execute_reply.started":"2022-10-25T19:44:25.369681Z","shell.execute_reply":"2022-10-25T19:44:45.743791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"block_height, block_width = map(int, \"16 16\".split())\nhoriz_blocks_num, vert_blocks_num, total_blocks_num = get_blocks_params(block_height, block_width, IMAGE_SIZE)  \nprint('Total number of blocks per image - {}'.format(total_blocks_num))","metadata":{"id":"uabT4PCa7Yew","outputId":"2460bf6c-4817-4cec-c7a7-9fbee88b504d","execution":{"iopub.status.busy":"2022-10-25T19:44:45.746589Z","iopub.execute_input":"2022-10-25T19:44:45.746964Z","iopub.status.idle":"2022-10-25T19:45:08.549562Z","shell.execute_reply.started":"2022-10-25T19:44:45.746916Z","shell.execute_reply":"2022-10-25T19:45:08.548500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert dataset with images into dataset with blocks. Each block has height and width entered earlier.","metadata":{}},{"cell_type":"code","source":"images_num = train_data.shape[0]  \ndata_with_blocks = np.zeros((total_blocks_num * images_num, block_height * block_width * 3))\n\nfor image_index in range(images_num):\n    pic = train_data[image_index]\n    for vert_index in range(vert_blocks_num):\n        for horiz_index in range(horiz_blocks_num):\n            data_with_blocks[total_blocks_num * image_index + horiz_blocks_num * vert_index + horiz_index, :] = \\\n                             pic[block_width * vert_index : block_width * (vert_index + 1),\\\n                                  block_height * horiz_index : block_height * (horiz_index + 1), :]\\\n                                  .reshape(block_height * block_width * 3)\n            \nprint(\"Shape of the data separated by blocks - {}\".format(data_with_blocks.shape))","metadata":{"execution":{"iopub.status.busy":"2022-10-25T19:47:15.000117Z","iopub.execute_input":"2022-10-25T19:47:15.000506Z","iopub.status.idle":"2022-10-25T19:47:18.563299Z","shell.execute_reply.started":"2022-10-25T19:47:15.000453Z","shell.execute_reply":"2022-10-25T19:47:18.562279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Neural network modeling**","metadata":{}},{"cell_type":"code","source":"class RecyclingNN():\n    def __init__(self, block_height : int, block_width : int,\\\n                 compression_factor : int = 3, alpha : float = 5*10e-5) -> None:\n        self.alpha = alpha\n        self.W1 = np.random.normal(0., pow(3 * block_width * block_height // compression_factor, -0.5),\\\n                                   size=(3 * block_width * block_height, 3 * block_width * block_height // compression_factor))\n        self.W2 = self.W1.T       \n        self.compression_factor = compression_factor\n\n    def forward(self, X : np.array, return_compressed=False) -> np.array:\n        splitted_pic = []  # blocks array\n        for vert_block_index in range(vert_blocks_num):\n                for horiz_block_index in range(horiz_blocks_num):\n                    splitted_pic.append(X[block_width * vert_block_index : block_width * (vert_block_index + 1),\\\n                                          block_height * horiz_block_index : block_height * (horiz_block_index + 1), :]\\\n                                          .reshape(block_height * block_width * 3) * 2 - 1)\n        encoded_pic = []  \n        for block in splitted_pic:\n            encoded_pic.append(block @ self.W1)\n        X = np.array(encoded_pic)\n        if return_compressed:\n            compression_factor = self.compression_factor\n            compres_factor_over_axis = compression_factor // 2\n            compress_image_shape = (IMAGE_SHAPE[0] // compres_factor_over_axis, IMAGE_SIZE // compres_factor_over_axis, 3)\n            compressed_pic = np.zeros(compress_image_shape)\n            compres_block_height = block_height // compres_factor_over_axis\n            compres_block_width = block_width // compres_factor_over_axis\n\n            compress_horiz_blocks_num, compress_vert_bloks_num, _ = get_blocks_params(\n                compres_block_height,\n                compres_block_width,\n                IMAGE_SIZE // compres_factor_over_axis\n            )\n\n            for vert_index in range(compress_vert_bloks_num):\n                for horiz_index in range(compress_horiz_blocks_num):\n                    compressed_pic[vert_index * compres_block_width : (vert_index + 1) * compres_block_width,\\\n                                   horiz_index * compres_block_height : (horiz_index + 1) * compres_block_height] = \\\n                                   X[vert_index * compres_block_width + horiz_index].reshape(compres_block_height, compres_block_width, 3) / 2 + 5.\n        \n        \n        pic = np.zeros(IMAGE_SHAPE)\n        for vert_block_index in range(vert_blocks_num):\n            for horiz_block_index in range(horiz_blocks_num):\n                pic[vert_block_index * block_width : (vert_block_index + 1) * block_width,\\\n                    horiz_block_index * block_height : (horiz_block_index + 1) * block_height] = \\\n                    (X[vert_block_index * block_width + horiz_block_index] @ self.W2).reshape(block_height, block_width, 3) / 2 + .5\n        if return_compressed:\n            return compressed_pic, pic\n        else:\n            return pic\n        \n    def save_weights(self):\n        np.savetxt('w1.csv', self.W1, delimiter=',')\n        np.savetxt('w2.csv', self.W2, delimiter=',')\n        \n    def upload_weights(self, path=\"../input/weights-for-rnn/\"):\n        self.W1 = np.loadtxt(open(path + 'w1.csv'), delimiter=\",\")\n        self.W2 = np.loadtxt(open(path + 'w2.csv'), delimiter=\",\")\n        \n    def backprop(self, X):\n        compressed = (X @ self.W1)[np.newaxis]\n        output = np.dot(compressed, self.W2)\n        error = (output - X)\n        self.W2 -= self.alpha * np.dot(compressed.T, error)\n        X = X[np.newaxis]\n        self.W1 -= self.alpha * np.dot(np.dot(X.T, error), self.W2.T)\n        return np.abs(error).sum()\n\n    def __call__(self, X, return_compressed=False):\n        return self.forward(X, return_compressed)","metadata":{"id":"UXJQHrd48WoC","execution":{"iopub.status.busy":"2022-10-25T20:15:23.067522Z","iopub.execute_input":"2022-10-25T20:15:23.067928Z","iopub.status.idle":"2022-10-25T20:15:23.085671Z","shell.execute_reply.started":"2022-10-25T20:15:23.067896Z","shell.execute_reply":"2022-10-25T20:15:23.084780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here you can upload pretrained weghts for NN where compression factor is 3. ","metadata":{}},{"cell_type":"code","source":"nn = RecyclingNN(block_height, block_width, 4, alpha=5e-5)\n#option = input(\"Upload weights: yes/no - \")\n#if option == 'yes':\n#    nn.upload_weights()","metadata":{"execution":{"iopub.status.busy":"2022-10-25T20:55:36.038470Z","iopub.execute_input":"2022-10-25T20:55:36.038866Z","iopub.status.idle":"2022-10-25T20:55:39.264390Z","shell.execute_reply.started":"2022-10-25T20:55:36.038834Z","shell.execute_reply":"2022-10-25T20:55:39.263426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Training process...**","metadata":{}},{"cell_type":"code","source":"error_values = []\ntrain_size = 70000 #int(input(\"Input train data size (<{})\".format(data_with_blocks.shape[0])))\nassert train_size < data_with_blocks.shape[0], \"Wrong train size\"","metadata":{"id":"j4G_0G3W8WtG","execution":{"iopub.status.busy":"2022-10-25T20:55:41.096769Z","iopub.execute_input":"2022-10-25T20:55:41.097716Z","iopub.status.idle":"2022-10-25T20:55:47.362506Z","shell.execute_reply.started":"2022-10-25T20:55:41.097673Z","shell.execute_reply":"2022-10-25T20:55:47.361529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for block_index in tqdm(range(train_size)):\n    error_values.append(nn.backprop(data_with_blocks[block_index]))","metadata":{"execution":{"iopub.status.busy":"2022-10-25T20:56:52.547716Z","iopub.execute_input":"2022-10-25T20:56:52.548136Z","iopub.status.idle":"2022-10-25T21:03:22.068850Z","shell.execute_reply.started":"2022-10-25T20:56:52.548099Z","shell.execute_reply":"2022-10-25T21:03:22.067537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(error_values);","metadata":{"id":"vb9zeKOieAjf","outputId":"6fb5525c-196a-49be-d8f6-35252f7c7a17","execution":{"iopub.status.busy":"2022-10-25T21:04:10.662416Z","iopub.execute_input":"2022-10-25T21:04:10.663144Z","iopub.status.idle":"2022-10-25T21:04:11.461654Z","shell.execute_reply.started":"2022-10-25T21:04:10.663108Z","shell.execute_reply":"2022-10-25T21:04:11.460655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#network testing\nmatplotlib.rcParams['figure.figsize'] = [12, 30]\nfig, axes = plt.subplots(10, 2)\n\nfor row_ind in range(10):\n    pic = train_data[np.random.randint(0, train_data.shape[0])]\n    test = nn(pic)\n    axes[row_ind][0].imshow(pic)\n    axes[row_ind][1].imshow(test)\naxes[0][0].set_title(\"Input\")\naxes[0][1].set_title(\"Output\");","metadata":{"id":"ji3Qny0-8WyC","outputId":"0204a516-c654-4488-de37-c1f84caeadd7","execution":{"iopub.status.busy":"2022-10-25T21:04:17.944818Z","iopub.execute_input":"2022-10-25T21:04:17.945181Z","iopub.status.idle":"2022-10-25T21:04:20.501989Z","shell.execute_reply.started":"2022-10-25T21:04:17.945150Z","shell.execute_reply":"2022-10-25T21:04:20.497630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Compressed pictures visualising**","metadata":{}},{"cell_type":"code","source":"matplotlib.rcParams['figure.figsize'] = [12, 12]\n\nimage_ind = np.random.randint(0, train_data.shape[0])\npic = train_data[image_ind]\ncompressed, test = nn(pic, True)\n\n#np.savetxt(\"{}_compr.csv\".format(image_ind), compressed, delimiter=',')\nfig, axs = plt.subplots(1,3)\naxs[0].imshow(pic)\naxs[1].imshow(compressed)\naxs[2].imshow(test)\naxs[0].set_title(\"Input\")\naxs[1].set_title(\"Compressed image\")\naxs[2].set_title(\"Output\");","metadata":{"execution":{"iopub.status.busy":"2022-10-25T21:04:37.612628Z","iopub.execute_input":"2022-10-25T21:04:37.613323Z","iopub.status.idle":"2022-10-25T21:04:38.407240Z","shell.execute_reply.started":"2022-10-25T21:04:37.613285Z","shell.execute_reply":"2022-10-25T21:04:38.406345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Average loss calculating**","metadata":{}},{"cell_type":"code","source":"err_sum = 0.\nfor image in train_data:\n    err_sum += np.abs(nn(image) - image).sum()\nerr_sum / train_data.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}